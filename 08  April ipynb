{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb73fe3-9b31-4552-9dbe-ef8ce552b56f",
   "metadata": {},
   "source": [
    "\n",
    "Question 1\n",
    "\n",
    "Question 1 : What is relationship between polynomial funtions and kernel functions in machine learning algorithms ?\n",
    "Answer :\n",
    "Polynomial functions and kernel functions are both commonly used in machine learning algorithms, but they have different roles.\n",
    "Polynomial functions are a type of function that can be used to fit data by using a polynomial equation to model the relationship between the input and output variables. In the context of machine learning, polynomial functions are often used as basis functions in linear regression models, where they are used to transform the input data into a higher-dimensional space so that linear decision boundaries can be more easily defined.\n",
    "Kernel functions, on the other hand, are used to define similarity measures between pairs of data points in a high-dimensional space. In machine learning, kernel functions are commonly used in kernel methods, such as support vector machines (SVMs) and kernelized ridge regression, to transform the input data into a high-dimensional space where linear decision boundaries can be more easily defined.\n",
    "One type of kernel function that is often used in kernel methods is the polynomial kernel, which computes the similarity between two data points as the dot product of their feature representations raised to a certain power (i.e., a polynomial function). This allows the kernel method to implicitly define nonlinear decision boundaries in the original input space, without the need to explicitly compute the high-dimensional feature space.\n",
    "In summary, while polynomial functions and kernel functions are both used in machine learning algorithms, they serve different purposes. Polynomial functions are used as basis functions in linear regression models, while kernel functions are used to define similarity measures between pairs of data points in a high-dimensional space, often as part of kernel methods.\n",
    "\n",
    "Question 2\n",
    "\n",
    "Question 2 : How can we implement SVM with polynomial kernel in Python using Scikit-learn library?\n",
    "Answer :\n",
    "Here's an example of how to implement an SVM with a polynomial kernel in Python using the Scikit-learn library:\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a random dataset for demonstration purposes\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2,n_informative=5 ,random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "svm_classifier = svm.SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's accuracy on the test data\n",
    "accuracy = svm_classifier.score(X_test, y_test)\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "Testing Accuracy: 0.895\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cf,annot=True,fmt='d')\n",
    "<Axes: >\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.87      0.90       112\n",
    "           1       0.85      0.93      0.89        88\n",
    "\n",
    "    accuracy                           0.90       200\n",
    "   macro avg       0.89      0.90      0.89       200\n",
    "weighted avg       0.90      0.90      0.90       200\n",
    "\n",
    "\n",
    "Question 3\n",
    "\n",
    "Question 3 : How does the increasing value of epsilon affect the number of support vectors in SVR?\n",
    "Answer :\n",
    "In Support Vector Regression (SVR), the parameter epsilon controls the width of the epsilon-insensitive tube, which is the region where errors are not penalized. Specifically, any training data point within the epsilon-insensitive tube does not contribute to the loss function.\n",
    "Increasing the value of epsilon can affect the number of support vectors in SVR in a couple of ways:\n",
    "Fewer support vectors: As the value of epsilon increases, the width of the epsilon-insensitive tube also increases. This means that fewer data points will fall outside of the tube and become support vectors. As a result, increasing epsilon tends to reduce the number of support vectors.\n",
    "\n",
    "More support vectors: On the other hand, increasing epsilon can also cause some data points that were previously outside of the tube to move inside the tube and become support vectors. This is because increasing epsilon can make the SVR model more tolerant to errors and allow more data points to be within the tube. In some cases, this can lead to an increase in the number of support vectors.\n",
    "\n",
    "Overall, the effect of increasing epsilon on the number of support vectors in SVR will depend on the specific dataset and the other hyperparameters of the model. In practice, it is often necessary to tune the value of epsilon along with other hyperparameters to achieve the best performance.\n",
    "\n",
    "Question 4\n",
    "\n",
    "Question 4 : How does the choice of kernel function, C parameter, epsilon parameter affect the performance of SVR? Can you explain how each parameter works and provide examples of when you might increase or decrease the value?\n",
    "Answer :\n",
    "The choice of kernel function, C parameter, and epsilon parameter can all have a significant impact on the performance of Support Vector Regression (SVR).\n",
    "Kernel Function: The kernel function determines how the SVR model transforms the input data into a higher-dimensional feature space. Different kernel functions have different properties and are better suited for different types of data.\n",
    "Choosing the right kernel function can greatly improve the performance of the SVR model. It's usually a good idea to try different kernel functions and choose the one that performs the best on the validation set.For example:\n",
    "\n",
    "* Linear kernel: Suitable for linearly separable data and large datasets\n",
    "* Polynomial kernel: Suitable for non-linear data and can capture complex relationships\n",
    "* Radial basis function (RBF) kernel: Suitable for non-linear data and can capture local and global patterns\n",
    "C Parameter: The C parameter controls the trade-off between the complexity of the model and the degree to which deviations larger than epsilon are penalized. A larger C parameter means that the model is more tolerant of errors and may overfit the data, while a smaller C parameter means that the model is less tolerant of errors and may underfit the data. In general:\n",
    "\n",
    "If the training data is noisy or has outliers, a larger C parameter may be needed to allow the model to fit the data better.\n",
    "If the training data is clean or has few outliers, a smaller C parameter may be sufficient to obtain good performance.\n",
    "Epsilon Parameter: The epsilon parameter controls the width of the epsilon-insensitive tube, which is the region where errors are not penalized. A larger epsilon parameter means that the model is more tolerant of errors and may allow more data points to be within the tube, while a smaller epsilon parameter means that the model is less tolerant of errors and may force more data points outside the tube. In general:\n",
    "\n",
    "If the training data is noisy or has many outliers, a larger epsilon parameter may be needed to allow the model to fit the data better.\n",
    "If the training data is clean or has few outliers, a smaller epsilon parameter may be sufficient to obtain good performance.\n",
    "Overall, the choice of kernel function, C parameter, and epsilon parameter should be based on the characteristics of the data and the desired level of complexity of the model. It's often a good idea to try different combinations of hyperparameters and choose the ones that perform the best on the validation set.\n",
    "\n",
    "Question 5\n",
    "\n",
    "Question 5 : Assignment\n",
    "Import necessary libraries and load the dataset\n",
    "\n",
    "Split the dataset into training and testing set\n",
    "\n",
    "Preprocess the data with any technique of your choice (eg. scaling, normaliazation)\n",
    "\n",
    "Create an instance of SVC Classifer and train it on training data\n",
    "\n",
    "Use trained Classifier to predict labels on testing data\n",
    "\n",
    "Evaluate the performance of classifier using any metric of your choice\n",
    "\n",
    "Tune Hyperparameter of SVC using GridSearchCV or RandomizedSearchCV to imporve the performance\n",
    "\n",
    "Train the tuned classifier for entire dataset\n",
    "\n",
    "Save the trained classifier to a file for future use\n",
    "\n",
    "Answer :\n",
    "Using dataset for cancer classification\n",
    "Dataset Source : https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "ID number\n",
    "Diagnosis (M = malignant, B = benign)\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "radius (mean of distances from center to points on the perimeter)\n",
    "texture (standard deviation of gray-scale values)\n",
    "perimeter\n",
    "area\n",
    "smoothness (local variation in radius lengths)\n",
    "compactness (perimeter^2 / area - 1.0)\n",
    "concavity (severity of concave portions of the contour)\n",
    "concave points (number of concave portions of the contour)\n",
    "symmetry\n",
    "fractal dimension (\"coastline approximatiom\")\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.read_csv('./data/cancer.csv')\n",
    "df.head()\n",
    "id\tdiagnosis\tradius_mean\ttexture_mean\tperimeter_mean\tarea_mean\tsmoothness_mean\tcompactness_mean\tconcavity_mean\tconcave points_mean\t...\ttexture_worst\tperimeter_worst\tarea_worst\tsmoothness_worst\tcompactness_worst\tconcavity_worst\tconcave points_worst\tsymmetry_worst\tfractal_dimension_worst\tUnnamed: 32\n",
    "0\t842302\tM\t17.99\t10.38\t122.80\t1001.0\t0.11840\t0.27760\t0.3001\t0.14710\t...\t17.33\t184.60\t2019.0\t0.1622\t0.6656\t0.7119\t0.2654\t0.4601\t0.11890\tNaN\n",
    "1\t842517\tM\t20.57\t17.77\t132.90\t1326.0\t0.08474\t0.07864\t0.0869\t0.07017\t...\t23.41\t158.80\t1956.0\t0.1238\t0.1866\t0.2416\t0.1860\t0.2750\t0.08902\tNaN\n",
    "2\t84300903\tM\t19.69\t21.25\t130.00\t1203.0\t0.10960\t0.15990\t0.1974\t0.12790\t...\t25.53\t152.50\t1709.0\t0.1444\t0.4245\t0.4504\t0.2430\t0.3613\t0.08758\tNaN\n",
    "3\t84348301\tM\t11.42\t20.38\t77.58\t386.1\t0.14250\t0.28390\t0.2414\t0.10520\t...\t26.50\t98.87\t567.7\t0.2098\t0.8663\t0.6869\t0.2575\t0.6638\t0.17300\tNaN\n",
    "4\t84358402\tM\t20.29\t14.34\t135.10\t1297.0\t0.10030\t0.13280\t0.1980\t0.10430\t...\t16.67\t152.20\t1575.0\t0.1374\t0.2050\t0.4000\t0.1625\t0.2364\t0.07678\tNaN\n",
    "5 rows × 33 columns\n",
    "\n",
    "df.shape\n",
    "(569, 33)\n",
    "df.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 569 entries, 0 to 568\n",
    "Data columns (total 33 columns):\n",
    " #   Column                   Non-Null Count  Dtype  \n",
    "---  ------                   --------------  -----  \n",
    " 0   id                       569 non-null    int64  \n",
    " 1   diagnosis                569 non-null    object \n",
    " 2   radius_mean              569 non-null    float64\n",
    " 3   texture_mean             569 non-null    float64\n",
    " 4   perimeter_mean           569 non-null    float64\n",
    " 5   area_mean                569 non-null    float64\n",
    " 6   smoothness_mean          569 non-null    float64\n",
    " 7   compactness_mean         569 non-null    float64\n",
    " 8   concavity_mean           569 non-null    float64\n",
    " 9   concave points_mean      569 non-null    float64\n",
    " 10  symmetry_mean            569 non-null    float64\n",
    " 11  fractal_dimension_mean   569 non-null    float64\n",
    " 12  radius_se                569 non-null    float64\n",
    " 13  texture_se               569 non-null    float64\n",
    " 14  perimeter_se             569 non-null    float64\n",
    " 15  area_se                  569 non-null    float64\n",
    " 16  smoothness_se            569 non-null    float64\n",
    " 17  compactness_se           569 non-null    float64\n",
    " 18  concavity_se             569 non-null    float64\n",
    " 19  concave points_se        569 non-null    float64\n",
    " 20  symmetry_se              569 non-null    float64\n",
    " 21  fractal_dimension_se     569 non-null    float64\n",
    " 22  radius_worst             569 non-null    float64\n",
    " 23  texture_worst            569 non-null    float64\n",
    " 24  perimeter_worst          569 non-null    float64\n",
    " 25  area_worst               569 non-null    float64\n",
    " 26  smoothness_worst         569 non-null    float64\n",
    " 27  compactness_worst        569 non-null    float64\n",
    " 28  concavity_worst          569 non-null    float64\n",
    " 29  concave points_worst     569 non-null    float64\n",
    " 30  symmetry_worst           569 non-null    float64\n",
    " 31  fractal_dimension_worst  569 non-null    float64\n",
    " 32  Unnamed: 32              0 non-null      float64\n",
    "dtypes: float64(31), int64(1), object(1)\n",
    "memory usage: 146.8+ KB\n",
    "## Dropping id and Unnamed: 32 column as statistically insignificant\n",
    "df = df.drop(labels=['id','Unnamed: 32'],axis=1)\n",
    "df.shape\n",
    "(569, 31)\n",
    "diagnosis_map = {'B':0,'M':1}\n",
    "df['diagnosis'] = df['diagnosis'].replace(diagnosis_map)\n",
    "df.head()\n",
    "diagnosis\tradius_mean\ttexture_mean\tperimeter_mean\tarea_mean\tsmoothness_mean\tcompactness_mean\tconcavity_mean\tconcave points_mean\tsymmetry_mean\t...\tradius_worst\ttexture_worst\tperimeter_worst\tarea_worst\tsmoothness_worst\tcompactness_worst\tconcavity_worst\tconcave points_worst\tsymmetry_worst\tfractal_dimension_worst\n",
    "0\t1\t17.99\t10.38\t122.80\t1001.0\t0.11840\t0.27760\t0.3001\t0.14710\t0.2419\t...\t25.38\t17.33\t184.60\t2019.0\t0.1622\t0.6656\t0.7119\t0.2654\t0.4601\t0.11890\n",
    "1\t1\t20.57\t17.77\t132.90\t1326.0\t0.08474\t0.07864\t0.0869\t0.07017\t0.1812\t...\t24.99\t23.41\t158.80\t1956.0\t0.1238\t0.1866\t0.2416\t0.1860\t0.2750\t0.08902\n",
    "2\t1\t19.69\t21.25\t130.00\t1203.0\t0.10960\t0.15990\t0.1974\t0.12790\t0.2069\t...\t23.57\t25.53\t152.50\t1709.0\t0.1444\t0.4245\t0.4504\t0.2430\t0.3613\t0.08758\n",
    "3\t1\t11.42\t20.38\t77.58\t386.1\t0.14250\t0.28390\t0.2414\t0.10520\t0.2597\t...\t14.91\t26.50\t98.87\t567.7\t0.2098\t0.8663\t0.6869\t0.2575\t0.6638\t0.17300\n",
    "4\t1\t20.29\t14.34\t135.10\t1297.0\t0.10030\t0.13280\t0.1980\t0.10430\t0.1809\t...\t22.54\t16.67\t152.20\t1575.0\t0.1374\t0.2050\t0.4000\t0.1625\t0.2364\t0.07678\n",
    "5 rows × 31 columns\n",
    "\n",
    "df.diagnosis.value_counts()\n",
    "0    357\n",
    "1    212\n",
    "Name: diagnosis, dtype: int64\n",
    "df.diagnosis.value_counts().plot(kind='bar')\n",
    "<Axes: >\n",
    "\n",
    "Split the data for training and testing set\n",
    "## Seperate dependent and independent variable\n",
    "X = df.drop(labels=['diagnosis'],axis=1)\n",
    "Y = df[['diagnosis']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y,test_size=0.3, random_state=42, stratify=Y)\n",
    "xtrain.shape\n",
    "(398, 30)\n",
    "xtest.shape\n",
    "(171, 30)\n",
    "Preprocessing the data with StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "xtrain = pd.DataFrame(scaler.fit_transform(xtrain),columns=xtrain.columns)\n",
    "xtest = pd.DataFrame(scaler.transform(xtest),columns=xtest.columns)\n",
    "xtrain.head()\n",
    "radius_mean\ttexture_mean\tperimeter_mean\tarea_mean\tsmoothness_mean\tcompactness_mean\tconcavity_mean\tconcave points_mean\tsymmetry_mean\tfractal_dimension_mean\t...\tradius_worst\ttexture_worst\tperimeter_worst\tarea_worst\tsmoothness_worst\tcompactness_worst\tconcavity_worst\tconcave points_worst\tsymmetry_worst\tfractal_dimension_worst\n",
    "0\t1.705820\t1.049745\t2.121295\t1.669337\t2.276458\t4.544295\t3.539139\t2.848393\t4.032390\t2.639773\t...\t1.459510\t0.949589\t1.868176\t1.306840\t1.335383\t2.313855\t2.346427\t2.049399\t3.944281\t0.866554\n",
    "1\t0.536388\t-0.909945\t0.569095\t0.390316\t-0.065868\t0.644945\t0.393543\t0.557002\t-0.116781\t-0.401530\t...\t0.508294\t-0.645315\t0.501917\t0.330087\t0.477013\t1.242091\t1.052574\t1.255850\t0.167978\t0.405242\n",
    "2\t-0.131456\t-0.993336\t-0.148848\t-0.211543\t-0.916169\t-0.508574\t-0.567530\t-0.606645\t-0.079867\t-0.512454\t...\t-0.362451\t-1.028485\t-0.280415\t-0.399387\t-0.196219\t0.368661\t-0.080795\t-0.140014\t0.741988\t0.687521\n",
    "3\t0.928077\t1.418055\t0.925405\t0.828546\t0.329734\t0.223748\t0.983188\t0.443947\t-1.866520\t-0.555982\t...\t0.365921\t0.351910\t0.386082\t0.243539\t-0.330866\t-0.464721\t0.030311\t-0.072253\t-2.040715\t-0.861167\n",
    "4\t0.144699\t-0.972488\t0.158315\t-0.009697\t1.205760\t0.585041\t0.137701\t0.562858\t1.116158\t0.117991\t...\t0.008957\t-1.257732\t0.059367\t-0.140450\t-0.187804\t0.359126\t-0.064176\t0.376471\t0.373873\t0.047726\n",
    "5 rows × 30 columns\n",
    "\n",
    "xtest.head()\n",
    "radius_mean\ttexture_mean\tperimeter_mean\tarea_mean\tsmoothness_mean\tcompactness_mean\tconcavity_mean\tconcave points_mean\tsymmetry_mean\tfractal_dimension_mean\t...\tradius_worst\ttexture_worst\tperimeter_worst\tarea_worst\tsmoothness_worst\tcompactness_worst\tconcavity_worst\tconcave points_worst\tsymmetry_worst\tfractal_dimension_worst\n",
    "0\t0.113702\t-0.022757\t0.096063\t0.012384\t-0.832738\t-0.461400\t-0.004036\t-0.491044\t-1.257434\t-0.724475\t...\t0.000703\t0.404309\t0.020756\t-0.092937\t-0.978852\t0.079425\t0.493724\t-0.282461\t-0.686799\t-0.506946\n",
    "1\t-0.582321\t-0.124679\t-0.624337\t-0.594570\t-0.834128\t-0.836920\t-0.999032\t-1.019701\t-0.954736\t-0.300434\t...\t-0.548155\t0.186524\t-0.619604\t-0.566124\t-0.137312\t-0.745058\t-1.086629\t-0.960215\t-0.048836\t-0.166454\n",
    "2\t-1.794022\t1.181780\t-1.801388\t-1.342789\t-3.005421\t-1.104989\t-1.091673\t-1.235829\t-0.836610\t-0.530708\t...\t-1.411472\t0.728530\t-1.432825\t-1.085410\t-1.775790\t-1.194868\t-1.300578\t-1.727112\t-0.062875\t-0.739798\n",
    "3\t-0.869748\t-0.604178\t-0.859420\t-0.798682\t0.823368\t-0.460651\t-0.715928\t-0.604353\t-0.367798\t0.109566\t...\t-0.801951\t0.085001\t-0.815929\t-0.727209\t0.199304\t-0.662419\t-0.793957\t-0.608162\t0.135222\t-0.277388\n",
    "4\t-0.387886\t-0.634291\t-0.384750\t-0.457270\t1.157092\t0.169460\t-0.613048\t-0.473220\t1.130923\t0.506930\t...\t-0.381022\t-0.684614\t-0.409022\t-0.457498\t0.645321\t-0.346484\t-0.624925\t-0.515707\t0.249088\t0.093857\n",
    "5 rows × 30 columns\n",
    "\n",
    "## Saving the scaler to pickle file to save for future use\n",
    "import pickle\n",
    "with open('scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler,file=f)\n",
    "Create an instance of SVC and train the model\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(xtrain,ytrain.values.flatten())\n",
    "SVC(kernel='linear')\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "Use trained classifier to predict labels on testing data\n",
    "ypred_test = svc.predict(xtest)\n",
    "ypred_test[0:5]\n",
    "array([0, 0, 0, 0, 0], dtype=int64)\n",
    "Evaluate model performance on base model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf = confusion_matrix(ytest,ypred_test)\n",
    "sns.heatmap(cf,annot=True,fmt='d')\n",
    "<Axes: >\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,ypred_test))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      1.00      0.97       107\n",
    "           1       1.00      0.91      0.95        64\n",
    "\n",
    "    accuracy                           0.96       171\n",
    "   macro avg       0.97      0.95      0.96       171\n",
    "weighted avg       0.97      0.96      0.96       171\n",
    "\n",
    "Hyperparameter tuning with GridSearchCV\n",
    "parameters = {\n",
    "    'C':[0.1,1,10,100,1000],\n",
    "    'gamma':[1,0.1,0.01,0.001,0.0001],\n",
    "    'kernel':['linear']\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gscv = GridSearchCV(SVC(),param_grid=parameters,refit=True,scoring='f1',cv=5,verbose=3)\n",
    "gscv.fit(xtrain,ytrain.values.flatten())\n",
    "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
    "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.949 total time=   0.0s\n",
    "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.947 total time=   0.0s\n",
    "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.949 total time=   0.0s\n",
    "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.947 total time=   0.0s\n",
    "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.949 total time=   0.0s\n",
    "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.947 total time=   0.0s\n",
    "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.949 total time=   0.0s\n",
    "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.947 total time=   0.0s\n",
    "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.949 total time=   0.0s\n",
    "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.947 total time=   0.0s\n",
    "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.966 total time=   0.0s\n",
    "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.906 total time=   0.0s\n",
    "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.933 total time=   0.0s\n",
    "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.933 total time=   0.0s\n",
    "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.933 total time=   0.0s\n",
    "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.933 total time=   0.0s\n",
    "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.933 total time=   0.0s\n",
    "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.931 total time=   0.0s\n",
    "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.903 total time=   0.0s\n",
    "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.983 total time=   0.0s\n",
    "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.909 total time=   0.0s\n",
    "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.926 total time=   0.0s\n",
    "GridSearchCV(cv=5, estimator=SVC(),\n",
    "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
    "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                         'kernel': ['linear']},\n",
    "             scoring='f1', verbose=3)\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "gscv.best_params_\n",
    "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
    "gscv.best_score_\n",
    "0.9536566071398516\n",
    "best_svc = gscv.best_estimator_\n",
    "best_svc\n",
    "SVC(C=0.1, gamma=1, kernel='linear')\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "# Evaluating best estimator\n",
    "ypred_test = best_svc.predict(xtest)\n",
    "cf_best = confusion_matrix(ytest,ypred_test)\n",
    "sns.heatmap(cf_best,annot=True,fmt='d')\n",
    "<Axes: >\n",
    "\n",
    "# Classification report for tuned model\n",
    "print('Classification report for tuned model :\\n')\n",
    "print(classification_report(ytest,ypred_test))\n",
    "Classification report for tuned model :\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      1.00      0.99       107\n",
    "           1       1.00      0.95      0.98        64\n",
    "\n",
    "    accuracy                           0.98       171\n",
    "   macro avg       0.99      0.98      0.98       171\n",
    "weighted avg       0.98      0.98      0.98       171\n",
    "\n",
    "Model Test F1 score imporved from 0.96 to 0.98 on test data\n",
    "Training the best estimator on entire dataset\n",
    "gscv.best_params_\n",
    "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
    "final_svc = SVC(kernel='linear',C=0.1,gamma=1)\n",
    "final_svc.fit(X,Y.values.flatten())\n",
    "SVC(C=0.1, gamma=1, kernel='linear')\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "Save the trained classifier file for future use\n",
    "import pickle\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(final_svc,file=f)\n",
    "Pickle file links\n",
    "scaler.pkl\n",
    "model.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
